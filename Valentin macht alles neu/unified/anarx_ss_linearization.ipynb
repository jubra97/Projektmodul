{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANARX-Linearisierung\n",
    "\n",
    "Vorraussetzung:\n",
    "\n",
    "Sei $\\mathbf{x}(t) = \\begin{bmatrix}x_1(t), & \\dots & ,x_n(t)\\end{bmatrix}$ und $\\mathbf{u}(t) = \\begin{bmatrix}u_1,(t) & \\dots & ,u_n(t)\\end{bmatrix}$\n",
    "\n",
    "Torch ANARX-Modell mit $n$ Subnetzen $N_n$ zusammengefasst als $\\mathbf{N}(\\mathbf{x}, \\mathbf{u})=\\begin{bmatrix}N_1(x_1, \\mathbf{u}) \\\\ \\vdots \\\\ N_{n-1}(x_{n-1}, \\mathbf{u}) \\\\ N_n(\\mathbf{u})\\end{bmatrix}$\n",
    "\n",
    "Sei $U_n = \\delta_{i+1,j}$ die obere Verschiebungsmatrix, dann gilt für die Zustandsübergangsfunktion:\n",
    "\n",
    "$\\mathbf{x}(t+1) = U_n \\cdot \\mathbf{x}(t) + N\\left(\\mathbf{x}(t), \\mathbf{u}\\left(t+1\\right)\\right)$\n",
    "\n",
    "bzw.:\n",
    "\n",
    "$F(\\mathbf{x},\\mathbf{u}) = U_n \\cdot \\mathbf{x} + N(\\mathbf{x}, \\mathbf{u})$\n",
    "\n",
    "Dann kann die Linearisierung von $F$ im Punkt $(\\mathbf{x}_0, \\mathbf{u_0}) $ wie folgt bestimmt werden:\n",
    "\n",
    "$F_L(\\mathbf{x}_0+\\Delta \\mathbf{x}, \\mathbf{u}_0+ \\Delta \\mathbf{u})=\\left.\\dfrac{\\partial F}{\\partial \\mathbf{x},\\mathbf{u}}\\right|_{(\\mathbf{x}_0, \\mathbf{u_0})} \\cdot \\Delta  \\mathbf{x} + \\left.\\dfrac{\\partial F}{\\partial \\mathbf{x},\\mathbf{u}}\\right|_{(\\mathbf{x}_0, \\mathbf{u_0})} \\cdot \\Delta  \\mathbf{u} + F(\\mathbf{x}, \\mathbf{u})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 3., 0.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "A = np.array([1,2,3])\n",
    "B = np.zeros([3,3])\n",
    "B[0,1] = 1\n",
    "B[1,2] = 1\n",
    "np.matmul(B,A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0059])\n",
      "tensor([0.0168])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from ANARX import LAGNET\n",
    "\n",
    "# Beispieldaten\n",
    "x = torch.tensor([2.], requires_grad=True)\n",
    "u = torch.tensor([3.], requires_grad=True)\n",
    "\n",
    "# Hier wird als Beispiel ein Subnetz aus der ANARX Klasse erzeugt\n",
    "# Der Code unten funktioniert allerdings für beliebige torch.Tensor-wertige Funktionen\n",
    "N = LAGNET(2, n_hidden=2, layersize=3, afunc=torch.tanh, bias=True)\n",
    "\n",
    "result = N(torch.cat((x,u))) # Auswertung von N\n",
    "result.backward() # Beim Backward-Pass bestimmt Autograd die Gradienten\n",
    "\n",
    "# Die Gradienten werden in der .grad-Property der Tensoren gespeichert\n",
    "print(x.grad)\n",
    "print(u.grad)\n",
    "\n",
    "# Wenn nur die Jacobimatrix benötigt wird kann sie mit diesem Befehl direkt bestimmt werden\n",
    "J = torch.autograd.functional.jacobian(N, torch.cat((x,u)))\n",
    "\n",
    "# Die Ergebnisse der Methoden stimmen überein\n",
    "assert torch.equal(J.squeeze(), torch.cat((x.grad,u.grad)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "065d846d6ebaa483d35d8a16a352bc8e0fee095aa1ce42ceeff74c200bef19a0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('Projektmodul')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
